library(ggplot2)
install.packages("swirl")
setwd("Temp/PracMachLearn")
```{r Libraries and Seed, cache = TRUE}
## Load the necessary libraries
suppressMessages(library(caret))
suppressMessages(library(randomForest))
suppressMessages(library(rpart))
## Assure reproducibility
set.seed(1234)
## Read the two files
data.in <- read.csv("data.csv", sep = ",", stringsAsFactors = FALSE,
na.strings=c("NA","#DIV/0!", ""))
data.in$classe <- as.factor(data.in$classe)
validate <- read.csv("validate.csv", sep = ",", stringsAsFactors = FALSE,
na.strings=c("NA","#DIV/0!", ""))
## Get only columns that have almost 95% correct values (not NAs) and delete
## personal data columns as: X, user_name, timestamp and windows (1:7)
data.clean <- data.in[,colSums(is.na(data.in)) <= (dim(data.in)[1] * 0.95)]
data.clean <- data.clean[, -c(1:7)]
validate <- validate[,colSums(is.na(data.in)) <= (dim(data.in)[1] * 0.95)]
validate <- validate[, -c(1:7)]
## Create training and test data
inTrain <- createDataPartition(y = data.clean$classe, p = 0.7, list = FALSE)
training <- data.clean[inTrain, ]
test <- data.clean[-inTrain, ]
## Look for Classe column to see if there are important differences
table(training$classe)
histogram(training$classe)
## 1. Decission Tree
fit.dt <- rpart(classe ~ ., data = training)
result.dt <- predict(fit.dt, test, type = "class")
## 2. Random Forest
fit.rf <- randomForest(classe ~ ., data = training, method = "class")
result.rf <- predict(fit.rf, test)
## Print a table with the Accuracy of each method
accuracy.dt <- confusionMatrix(result.dt, test$classe)$overall["Accuracy"]
accuracy.rf <- confusionMatrix(result.rf, test$classe)$overall["Accuracy"]
accuracy.dt
accuracy.rt
accuracy.rf
predict(fit.rf, validate, type = class)
names(data.clean)
names(validate)
predict(fit.rf, validate[,1:dim(validate)[2]-1], type = class)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: Libraries and Seed
## Load the necessary libraries
suppressMessages(library(caret))
suppressMessages(library(randomForest))
suppressMessages(library(rpart))
## Assure reproducibility
set.seed(1234)
# Chunk 3: Download Files
## Download the 2 files
url.data <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url.validate <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url.data, "data.csv")
download.file(url.validate, "validate.csv")
# Chunk 4: Getting and Cleaning Data
## Read the two files
data.in <- read.csv("data.csv", sep = ",", stringsAsFactors = FALSE,
na.strings=c("NA","#DIV/0!", ""))
data.in$classe <- as.factor(data.in$classe)
validate <- read.csv("validate.csv", sep = ",", stringsAsFactors = FALSE,
na.strings=c("NA","#DIV/0!", ""))
## Get only columns that have almost 95% correct values (not NAs) and delete
## personal data columns as: X, user_name, timestamp and windows (1:7)
data.clean <- data.in[,colSums(is.na(data.in)) <= (dim(data.in)[1] * 0.95)]
data.clean <- data.clean[, -c(1:7)]
validate <- validate[,colSums(is.na(data.in)) <= (dim(data.in)[1] * 0.95)]
validate <- validate[, -c(1:7)]
## Create training and test data
inTrain <- createDataPartition(y = data.clean$classe, p = 0.7, list = FALSE)
training <- data.clean[inTrain, ]
test <- data.clean[-inTrain, ]
## Look for Classe column to see if there are important differences
table(training$classe)
histogram(training$classe)
# Chunk 5: Fitting models and calculating Accuracy
## 1. Decission Tree
fit.dt <- rpart(classe ~ ., data = training)
result.dt <- predict(fit.dt, test, type = "class")
## 2. Random Forest
fit.rf <- randomForest(classe ~ ., data = training, method = "class")
result.rf <- predict(fit.rf, test)
## Calculate the Accuracy of each method
accuracy.dt <- confusionMatrix(result.dt, test$classe)$overall["Accuracy"]
accuracy.rf <- confusionMatrix(result.rf, test$classe)$overall["Accuracy"]
names(validation)
names(validate)
x <- validate[,1:52]
predict(fit.rf, validate[,1:dim(validate)[2]-1], type = class)
predict(fit.rf, x, type = class)
x
predict(fit.rf, x)
predict(fit.rf, validate)
